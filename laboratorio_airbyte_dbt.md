# Laborat√≥rio ‚Äî Ingest√£o CSV com Airbyte + Transforma√ß√£o com dbt

## üéØ Objetivos
- Instalar e configurar **dbt** e **Airbyte**.  
- Ingerir o CSV (dados de usinas) para o Snowflake via Airbyte.  
- Criar modelos dbt com base no dicion√°rio do arquivo.  

---

## üßë‚Äçüè´ Parte 1 ‚Äî Laborat√≥rio Guiado

### 1. Instala√ß√£o e configura√ß√£o preliminar
- **Snowflake**: execute o arquivo setup_lab_airbyte.sql
- **Airbyte**: j√° configurado antes ou use Docker Compose.  
- **dbt**:
  ```bash
  pip install dbt-snowflake
  dbt init laboratorio_dbt
  ```
  Configure o `profiles.yml` para apontar √† sua conta Snowflake:
  
  **Localiza√ß√£o do arquivo**: `~/.dbt/profiles.yml` (Linux/Mac) ou `C:\Users\{username}\.dbt\profiles.yml` (Windows)
  
  **Conte√∫do do `profiles.yml`:**
  ```yaml
  laboratorio_dbt:
    outputs:
      dev:
        type: snowflake
        account: [sua_conta_snowflake]  # ex: ZBUHFWH-HY64747
        user: AIRBYTE_DEV
        password: [sua_senha]
        role: AIRBYTE_DEV
        database: LAB_AIRBYTE
        warehouse: LAB_WH_AIRBYTE
        schema: CORE
        threads: 4
        keepalives_idle: 240
    target: dev
  ```
  
  **Teste a conex√£o:**
  ```bash
  cd laboratorio_dbt
  dbt debug
  ```
  
  **Estrutura de pastas esperada:**
  ```
  laboratorio_dbt/
  ‚îú‚îÄ‚îÄ dbt_project.yml
  ‚îú‚îÄ‚îÄ models/
  ‚îÇ   ‚îî‚îÄ‚îÄ schema.yml
  ‚îî‚îÄ‚îÄ ~/.dbt/profiles.yml
  ```

---

### 2. Ingest√£o com Airbyte
- Fonte: CSV de disponibilidade de usinas (hor√°ria) a partir da URL `https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/disponibilidade_usina_ho/DISPONIBILIDADE_USINA_2025_08.csv`.  
- Destination: tabela `STAGING.DISPONIBILIDADE_USINA_2025_08`.  
- Verifique no Snowflake:
  ```sql
  SELECT * FROM STAGING.DISPONIBILIDADE_USINA_2025_08 LIMIT 5;
  ```

---

### 3. Cria√ß√£o de modelo transforma no dbt (com dicion√°rio)

**Exemplo `models/stg_usina_disp.sql`:**
```sql
SELECT
  id_subsistema,
  nom_estado,
  nom_usina,
  din_instante::TIMESTAMP       AS instante,
  val_potenciainstalada         AS pot_instalada_mw,
  val_dispoperacional           AS disp_operacional_mw,
  val_dispsincronizada          AS disp_sincronizada_mw
FROM {{ source('staging','disponibilidade_usina_2025_08') }};
```

**schema.yml**:
```yaml
sources:
  - name: staging
    tables:
      - name: disponibilidade_usina_2025_08

models:
  - name: stg_usina_disp
    columns:
      - name: instante
        tests: [not_null]
      - name: id_subsistema
        tests: [not_null]
```

Execute:
```bash
dbt run --select stg_usina_disp
dbt test --select stg_usina_disp
```

---

## üßë‚Äçüíª Parte 2 ‚Äî Atividades dos Estudantes

### Atividade A ‚Äî Ingest√£o de Novos Dados
- Configure o Airbyte para ingerir dados de mais dois meses. Para pegar os dados de outros meses, basta trocar na URL, por exemplo:
  - Julho: `https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/disponibilidade_usina_ho/DISPONIBILIDADE_USINA_2025_07.csv`
  - Setembro: `https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/disponibilidade_usina_ho/DISPONIBILIDADE_USINA_2025_09.csv`
- Crie uma tabela de destino para cada m√™s no schema `STAGING`.
- Atualize seu `schema.yml` para declarar as duas novas tabelas como fontes (`sources`).

### Atividade B ‚Äî Desenvolver Modelos de Dimens√£o (Core)
Com base nos dados extra√≠dos, crie os seguintes modelos dimensionais no schema `CORE`. 
**Importante**: cada dimens√£o deve ser constru√≠da a partir da uni√£o dos dados de **todos os meses** ingeridos para garantir que contenha todos os valores √∫nicos.

1.  **`dim_usina.sql`**:
    - Deve conter atributos √∫nicos de cada usina (`nom_usina`, `nom_tipocombustivel`, `ceg`).
    - Crie uma chave prim√°ria substituta (surrogate key) chamada `id_dim_usina` usando `dbt_utils.generate_surrogate_key`.

2.  **`dim_localidade.sql`**:
    - Deve conter atributos √∫nicos de localidade (`nom_subsistema`, `nom_estado`).
    - Crie uma chave prim√°ria substituta chamada `id_dim_localidade`.

3.  **`dim_tempo.sql`**:
    - Extraia componentes de data e hora da coluna `din_instante` (ano, m√™s, dia, hora).
    - Crie uma chave prim√°ria substituta a partir do pr√≥prio instante.

### Atividade C ‚Äî Desenvolver Modelo de Fatos (Core)
Crie o seguinte modelo de fatos no schema `CORE`:

1.  **`fact_disponibilidade.sql`**:
    - Crie um modelo de fatos centralizado que servir√° de base para as **agrega√ß√µes** necess√°rias para responder √†s perguntas de neg√≥cio.
    - **L√≥gica de Constru√ß√£o**:
        - Enrique√ßa os dados com as chaves das tabelas de dimens√£o (`dim_usina`, `dim_localidade`, `dim_tempo`).
        - Utilize uma unidade agregada de tempo (por exemplo: dia).
        - O modelo deve conter as m√©tricas (`pot_instalada_mw`, `disp_operacional_mw`, `disp_sincronizada_mw`) no seu gr√£o mais detalhado (usina, localidade, instante) para permitir m√°xima flexibilidade nas an√°lises.
    - **Perguntas a Responder (via Agrega√ß√£o)**: O modelo deve ser a fonte para responder a perguntas como:
        - Qual a disponibilidade operacional **total** por estado em um determinado m√™s?
        - Qual usina teve a **maior m√©dia** de pot√™ncia instalada no √∫ltimo trimestre?
        - Qual a **m√©dia** de disponibilidade sincronizada por hora do dia para usinas do tipo "Hidr√°ulica"?

### Atividade D ‚Äî Adicionar Testes de Qualidade
- No `schema.yml`, adicione testes para os novos modelos:
  - `unique` e `not_null` para as chaves prim√°rias de todas as tabelas de dimens√£o.
  - `relationships` na tabela de fatos para garantir que todas as chaves estrangeiras correspondam a um registro em suas respectivas tabelas de dimens√£o.

---

## ‚úÖ Crit√©rios de Avalia√ß√£o
- Configurar dbt e Airbyte sem ajuda.  
- Carregar m√∫ltiplos arquivos CSV corretamente via Airbyte.  
- Criar modelos dimensionais (dimens√µes e fatos) seguindo as boas pr√°ticas.
- Definir testes de qualidade para garantir a integridade referencial dos modelos.